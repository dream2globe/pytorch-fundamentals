{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expired-basis",
   "metadata": {},
   "source": [
    "# What are Tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-bennett",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-innocent",
   "metadata": {},
   "source": [
    "- GPU accelerators를 사용할 수 있는 점을 제외하고 numpy의 ndarrays와 유사함\n",
    "- 사실, tensors와 Numpy arrays는 종종 같은 메모리를 공유하기도 함\n",
    "- 자동 미분을 최적화하는 기능이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "about-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-church",
   "metadata": {},
   "source": [
    "## Initializing a Tensor\n",
    "\n",
    "### Directly from data\n",
    "- 데이터 형은 자동으로 추론됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "strong-handy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-bruce",
   "metadata": {},
   "source": [
    "### NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bearing-classics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-script",
   "metadata": {},
   "source": [
    "### From another tensor\n",
    "- 기존 tensor의 properties(shape, data type) 정보를 활용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nearby-distribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.5675, 0.4661],\n",
      "        [0.9169, 0.5502]])\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(x_ones)\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-thailand",
   "metadata": {},
   "source": [
    "### with random or constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "little-phrase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7313, 0.6241, 0.2426],\n",
      "        [0.2097, 0.6772, 0.0513]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(rand_tensor)\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-mandate",
   "metadata": {},
   "source": [
    "## Attributes of a Tensor\n",
    "- Tensor의 attribute은 shape, data type, and 저장된 장치를 표현함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "internal-founder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-letters",
   "metadata": {},
   "source": [
    "## Operations on Tensors\n",
    "- 100개 이상의 Tensor operation은 https://pytorch.org/docs/stable/torch.html 에서 확인 가능\n",
    "- 각 operation은 GPU를 활용할 수 있으며 일반적으로 GPU의 연산이 더욱 빠름\n",
    "- Tensor는 기본적으로 CPU을 사용하도록 생성되므로 `.to` 함수를 사용하여 명시적으로 GPU로 옮겨야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "perfect-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-forth",
   "metadata": {},
   "source": [
    "### Standard numpy-like indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "useful-sailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:  tensor([0.5370, 0.1508, 0.1293, 0.3405])\n",
      "First column:  tensor([0.5370, 0.6152, 0.0887, 0.8909])\n",
      "Last column:  tensor([0.3405, 0.5877, 0.3791, 0.8248])\n",
      "tensor([[0.5370, 0.0000, 0.0887, 0.8909],\n",
      "        [0.1508, 0.0000, 0.4380, 0.9449],\n",
      "        [0.1293, 0.0000, 0.3429, 0.0960],\n",
      "        [0.3405, 0.0000, 0.3791, 0.8248]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4, 4)\n",
    "print(\"First row: \", tensor[:, 0])\n",
    "print(\"First column: \", tensor[0, :])\n",
    "print(\"Last column: \", tensor[-1, :])\n",
    "\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-january",
   "metadata": {},
   "source": [
    "### Joining tensors\n",
    "- torch.cat: 차원이 증가하지 않음\n",
    "- torch.stack: 차원이 증가하면서 결합됨. `unsqueeze(0)` + `cat` 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "overall-product",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5370, 0.0000, 0.0887, 0.8909],\n",
      "        [0.1508, 0.0000, 0.4380, 0.9449],\n",
      "        [0.1293, 0.0000, 0.3429, 0.0960],\n",
      "        [0.3405, 0.0000, 0.3791, 0.8248],\n",
      "        [0.5370, 0.0000, 0.0887, 0.8909],\n",
      "        [0.1508, 0.0000, 0.4380, 0.9449],\n",
      "        [0.1293, 0.0000, 0.3429, 0.0960],\n",
      "        [0.3405, 0.0000, 0.3791, 0.8248],\n",
      "        [0.5370, 0.0000, 0.0887, 0.8909],\n",
      "        [0.1508, 0.0000, 0.4380, 0.9449],\n",
      "        [0.1293, 0.0000, 0.3429, 0.0960],\n",
      "        [0.3405, 0.0000, 0.3791, 0.8248]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=0) # row-wide\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "quick-genre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5370, 0.0000, 0.0887, 0.8909, 0.5370, 0.0000, 0.0887, 0.8909, 0.5370,\n",
      "         0.0000, 0.0887, 0.8909],\n",
      "        [0.1508, 0.0000, 0.4380, 0.9449, 0.1508, 0.0000, 0.4380, 0.9449, 0.1508,\n",
      "         0.0000, 0.4380, 0.9449],\n",
      "        [0.1293, 0.0000, 0.3429, 0.0960, 0.1293, 0.0000, 0.3429, 0.0960, 0.1293,\n",
      "         0.0000, 0.3429, 0.0960],\n",
      "        [0.3405, 0.0000, 0.3791, 0.8248, 0.3405, 0.0000, 0.3791, 0.8248, 0.3405,\n",
      "         0.0000, 0.3791, 0.8248]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.cat([tensor, tensor, tensor], dim=1) # column-wide\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "blond-alert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5370, 0.0000, 0.0887, 0.8909],\n",
      "         [0.1508, 0.0000, 0.4380, 0.9449],\n",
      "         [0.1293, 0.0000, 0.3429, 0.0960],\n",
      "         [0.3405, 0.0000, 0.3791, 0.8248]],\n",
      "\n",
      "        [[0.5370, 0.0000, 0.0887, 0.8909],\n",
      "         [0.1508, 0.0000, 0.4380, 0.9449],\n",
      "         [0.1293, 0.0000, 0.3429, 0.0960],\n",
      "         [0.3405, 0.0000, 0.3791, 0.8248]],\n",
      "\n",
      "        [[0.5370, 0.0000, 0.0887, 0.8909],\n",
      "         [0.1508, 0.0000, 0.4380, 0.9449],\n",
      "         [0.1293, 0.0000, 0.3429, 0.0960],\n",
      "         [0.3405, 0.0000, 0.3791, 0.8248]]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.stack([tensor, tensor, tensor], dim=0) # dim=0\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "interesting-arkansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[True, True, True, True],\n",
      "         [True, True, True, True],\n",
      "         [True, True, True, True],\n",
      "         [True, True, True, True]],\n",
      "\n",
      "        [[True, True, True, True],\n",
      "         [True, True, True, True],\n",
      "         [True, True, True, True],\n",
      "         [True, True, True, True]],\n",
      "\n",
      "        [[True, True, True, True],\n",
      "         [True, True, True, True],\n",
      "         [True, True, True, True],\n",
      "         [True, True, True, True]]])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.cat([tensor.unsqueeze(0), tensor.unsqueeze(0), tensor.unsqueeze(0)], dim=0)\n",
    "print(t3 == t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "legitimate-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5370, 0.0000, 0.0887, 0.8909],\n",
      "         [0.5370, 0.0000, 0.0887, 0.8909],\n",
      "         [0.5370, 0.0000, 0.0887, 0.8909]],\n",
      "\n",
      "        [[0.1508, 0.0000, 0.4380, 0.9449],\n",
      "         [0.1508, 0.0000, 0.4380, 0.9449],\n",
      "         [0.1508, 0.0000, 0.4380, 0.9449]],\n",
      "\n",
      "        [[0.1293, 0.0000, 0.3429, 0.0960],\n",
      "         [0.1293, 0.0000, 0.3429, 0.0960],\n",
      "         [0.1293, 0.0000, 0.3429, 0.0960]],\n",
      "\n",
      "        [[0.3405, 0.0000, 0.3791, 0.8248],\n",
      "         [0.3405, 0.0000, 0.3791, 0.8248],\n",
      "         [0.3405, 0.0000, 0.3791, 0.8248]]])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.stack([tensor, tensor, tensor], dim=1) # dim=1\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-madonna",
   "metadata": {},
   "source": [
    "## Arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "voluntary-panama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0899, 0.9616, 0.1854, 0.9513],\n",
       "        [0.9616, 1.1074, 0.2604, 0.9968],\n",
       "        [0.1854, 0.2604, 0.1435, 0.2533],\n",
       "        [0.9513, 0.9968, 0.2533, 0.9400]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬 곱\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "maritime-poultry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y1 == y2) & (y1 == y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "found-crime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2883, 0.0000, 0.0115, 0.3033],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0115, 0.0000, 0.1176, 0.0364],\n",
       "        [0.3033, 0.0000, 0.0364, 0.6804]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element-wise product\n",
    "z1 = tensor * tensor.T\n",
    "z2 = tensor.mul(tensor.T)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor.T, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "molecular-hudson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(z1 == z2) & (z1 == z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-aurora",
   "metadata": {},
   "source": [
    "### Single-element tensors\n",
    "아래 예제와 같이 모든 Tensor의 값이 하나로 합쳐지는 경우, `item()` 함수를 사용하여 Python 숫자형 값으로 젼환 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "presidential-washer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.162968635559082 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-tissue",
   "metadata": {},
   "source": [
    "### In-plale operations\n",
    "- 피연산자에 결과를 저장하는 함수를 의미하며, `_` suffix로 표현됨\n",
    "- 예를 들어 `x.copy_()`, `x.t_()`는 x를 변경함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-frequency",
   "metadata": {},
   "source": [
    "> **Note:** 메모리를 절약할 수는 있지만 즉시 연산 히스토리가 사라지기 때문에 주의해서 사용 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-rugby",
   "metadata": {},
   "source": [
    "## Bridge with NumPy\n",
    "CPU Tensor와 NumPy array는 메모리를 공유할 수 있음\n",
    " \n",
    "### Tensor to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "excellent-hostel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fatty-husband",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-madagascar",
   "metadata": {},
   "source": [
    "### NumPy array to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sticky-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "younger-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-pulse",
   "metadata": {},
   "source": [
    "# Load data with PyTorch Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "closing-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-basic",
   "metadata": {},
   "source": [
    "## Datasets and Dataloaders\n",
    "- 좀 더 읽기 쉽고 모듈화하기 위해 모델 학습코드와 데이터셋 코드가 결합지 않기를 원했음\n",
    "- Pytorch는 두 가지 데이터 기본 기능을 제공\n",
    "    - `torch.utils.data.DataLoader`\n",
    "    - `torch.utils.data.Dataset`\n",
    "- `Dataset`은 데이터와 레이블을 저장하고 `DataLoader`는 iterable 객체처럼 쉽게 읽을 수 있도록`Dataset`을 감싸는 형태\n",
    "\n",
    "### Loading a dataset\n",
    "- TorchVision을 활용하여 [Fashion-MNIST](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) 을 읽는 예제\n",
    "    - 60,000개의 학습 데이터와 10,000개의 테스트 데이터로 구성됨\n",
    "    - 28*28 grayscale image, 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "executed-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # data path\n",
    "    train=True,\n",
    "    download=True, # root에 데이터가 없는 경우 다운받음\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-newcastle",
   "metadata": {},
   "source": [
    "### Iterating and Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "based-bermuda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols*rows+1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-bulletin",
   "metadata": {},
   "source": [
    "## Creating a Custom Dataset for your files\n",
    "- `__init__`, `__len__`, and `__getitem__` 3가지 함수를 꼭 구현해 함\n",
    "    - `__init__`: images directory, annotation file, transforms 초기화\n",
    "    - `__dataset__`: sample 수를 반환\n",
    "    - `__getitem__`: `idx`에 해당하는 이미지와 레이블을 읽어서 반환\n",
    "- FashionMNIST dataset를 직접 호출하는 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "headed-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import torchvision.io as tvio\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotation_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotation_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = tvio.read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.transform\n",
    "        sample = {\"image\":image, \"label\":label}\n",
    "        return sample    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-november",
   "metadata": {},
   "source": [
    "## Preparing your data for training with DataLoaders\n",
    "\n",
    "- `Dataset`은 한 번에 하나의 샘플을 반환함\n",
    "- 모델을 학습하는 동안 minibatch\"를 사용함 (모델의 과적합을 방지하기 위해 매 epoch바다 데이터의 순서를 변경함)\n",
    "- Python의 multiprocessing을 사용하면 속도를 개선할 수 있음\n",
    "- DataLoader는 손쉬운 API를 통해 이러한 복합성을 추상화한 iterable임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "disabled-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "labeled-raleigh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Shirt\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {labels_map[label.item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-relevance",
   "metadata": {},
   "source": [
    "# Transform the data\n",
    "- 기계학습 알고리즘이 원하는 최종 처리된 형태의 데이터를 항상 얻을 수는 없기 때문에 학습에 알맞은 형태로 변환하는 경우가 많음\n",
    "- 모든 TrochVision dataset은 두 가지 Parameter(`transform`, `target_transform`)의 설정을 통해 [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)에서 제공하는 변환 함수를 사용할 수 있음 \n",
    "- FashonMNIST의 경우 PIL Image format으로 저장되어 있어 feature는 정규화된 tensor로, 레이블은 one-hot  encoded tensor의 변환이 필요함\n",
    "- 이를 위해 `ToTnesor`, `Lambda`를 사용할 예정임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "automated-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-adobe",
   "metadata": {},
   "source": [
    "### ToTensor()\n",
    "[ToTensor](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor)는 PIL image, Numpy ndarray를 `FloatTensor` 로 변환하며 [0., 1.] 구간의 값으로 스케일을 변경함\n",
    "### Lambda transforms\n",
    "사용자 정의 합수 적용 시에 사용하여 위의 예시에서는 정수값을 one-hot vector로 변환하는 사용자 합수를 대입하였음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-fusion",
   "metadata": {},
   "source": [
    "# Building the model layers\n",
    "## Build a neural network\n",
    "- [torch.nn](https://pytorch.org/docs/stable/nn.html) 네임스페이스는 사용자 고유의 신경망을 구성할 수 있는 모든 블럭을 제공함\n",
    "- 신경망은 다른 모듈(층)으로 구성된 그 자체이며, 중쳡된 구조는 복잡한 신경망을 쉽게 관리하고 생성할 수 있도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "behavioral-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-florence",
   "metadata": {},
   "source": [
    "### Get a hardware device for training\n",
    "GPU를 활용한 하드웨어 가속이 가능한지 확인하고 불가능하다면 CPU로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "moving-gazette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-flood",
   "metadata": {},
   "source": [
    "### Define the class\n",
    "\n",
    "- `nn.module`을 사용해서 신경망을 정의하고 `__init__`에서 layer들을 초기화\n",
    "- 모든 `nn.module` subclass 구현은 `forward` 함수 안에서 입력 데이터에 동작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "legitimate-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-basic",
   "metadata": {},
   "source": [
    "`NeuralNetwork` 인스턴스를 만들고 장치와 구조를 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "comic-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-stock",
   "metadata": {},
   "source": [
    "- 모델을 사용하기 위해, 입력 데이터를 통과시켜야 하며, 모델의 `forward` 함수을 실행하면 됨\n",
    "- 모델에 전달하만 백그라운드 연산에 의해 `forward` 함수가 실행되며, 직접 호출해서는 안됨\n",
    "- 모델의 호출은 각 범주의 예측값을 담은 10 차원 tensor를 반환함. 이를 nn.Softmax에 통화시기면 예측의 확률밀도를 얻을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "recorded-brake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([6], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "\n",
    "\"\"\"\n",
    "tensor([[0.0983, 0.1032, 0.1035, 0.0983, 0.0983, 0.0983, 0.0983, 0.1008, 0.1027,\n",
    "         0.0983]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
    "\"\"\"\n",
    "\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-makeup",
   "metadata": {},
   "source": [
    "### Model layers\n",
    "\n",
    "FashionMNIST model의 네트워크를 나누어서 살펴보고, 이미지 3개(28*28)가 포함된 미니배치를 네트워크에 통과시켜서 변화를 확인할 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "international-liability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-perception",
   "metadata": {},
   "source": [
    "#### nn.Flatten\n",
    "[nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)는 2D 28×28 이미지를 연속된 784픽셀 이미지로 전환(미니배치 차원(at dim=0)은 유지됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aggregate-makeup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-trailer",
   "metadata": {},
   "source": [
    "#### nn.Linear\n",
    "[linear layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)는 저장된 가중치와 편향을 사용하여 입력 데이터를 선형 변환함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "lined-three",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-stone",
   "metadata": {},
   "source": [
    "#### nn.ReLU\n",
    "비선형 활성 함수는 모델의 입력과 출력 사이의 복잡한 연결(비선형성)을 생성함. 이 모델에서는 [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)을 사용하였으나 다른 비성형 활성 함수를 사용할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "structural-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.1868,  0.0294, -0.0957, -0.3181,  0.0268,  0.1574, -0.5895, -0.5680,\n",
      "          0.4480,  0.1576, -0.2269, -0.1276,  0.4701,  0.0279, -0.4837, -0.1998,\n",
      "         -0.3038,  0.1281, -0.4609, -0.0361],\n",
      "        [-0.1722,  0.1283,  0.1081, -0.4835,  0.0278,  0.2807, -0.5667, -0.8886,\n",
      "          0.4338,  0.3818, -0.0741,  0.3561,  0.3050, -0.0107, -0.0197, -0.3315,\n",
      "         -0.4128,  0.1350, -0.2094, -0.0108],\n",
      "        [-0.0743, -0.2089, -0.2684,  0.1382,  0.0235,  0.1067, -0.5495, -0.7343,\n",
      "          0.5339,  0.1988, -0.0891,  0.2588,  0.3409, -0.3066, -0.0862, -0.2195,\n",
      "         -0.3100,  0.1488, -0.5675, -0.1088]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0294, 0.0000, 0.0000, 0.0268, 0.1574, 0.0000, 0.0000, 0.4480,\n",
      "         0.1576, 0.0000, 0.0000, 0.4701, 0.0279, 0.0000, 0.0000, 0.0000, 0.1281,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.1283, 0.1081, 0.0000, 0.0278, 0.2807, 0.0000, 0.0000, 0.4338,\n",
      "         0.3818, 0.0000, 0.3561, 0.3050, 0.0000, 0.0000, 0.0000, 0.0000, 0.1350,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1382, 0.0235, 0.1067, 0.0000, 0.0000, 0.5339,\n",
      "         0.1988, 0.0000, 0.2588, 0.3409, 0.0000, 0.0000, 0.0000, 0.0000, 0.1488,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-oracle",
   "metadata": {},
   "source": [
    "#### nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-barbados",
   "metadata": {},
   "source": [
    "[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)은 모듈 들의 순서를 정의하고, 데이터는 정의한 순서대로 모든 모듈을 통과함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "further-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "\n",
    "input_image - torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-glass",
   "metadata": {},
   "source": [
    "#### nn.Softmax\n",
    "신경망의 마지막 층에서는 범위가 [-infty, infty] 인 `logits`을 반환하므로 [nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)을 사용하여 [0, 1] 사이의 값 즉, 각 범주의 예측 확률변수로 나타낼 수 있음. `dim` parameter는 해당 축의 합이 1인 차원을 가리킴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "advisory-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-david",
   "metadata": {},
   "source": [
    "### Model parameters\n",
    "\n",
    "신경망의 많은 layer는 파라미터로 나타낼 수 있으며, 파라미터 학습 중 최적화됨. `nn.Module` 를 상속하면 자동으로 모델 내 파라미터들이 추적되며, 모든 파라미터는 모델의 `parameters()` 혹은 `named_parameters()` 함수로 접근할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "handy-processing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : Parameter containing:\n",
      "tensor([[-0.0161, -0.0268,  0.0353,  ..., -0.0151, -0.0063, -0.0239],\n",
      "        [-0.0340, -0.0287,  0.0081,  ..., -0.0284, -0.0040, -0.0190],\n",
      "        [-0.0247,  0.0351,  0.0263,  ..., -0.0092, -0.0182, -0.0018],\n",
      "        ...,\n",
      "        [-0.0269,  0.0083,  0.0353,  ..., -0.0325,  0.0254,  0.0244],\n",
      "        [-0.0162, -0.0263, -0.0021,  ..., -0.0343,  0.0221,  0.0070],\n",
      "        [-0.0064, -0.0164,  0.0136,  ...,  0.0260, -0.0352, -0.0176]],\n",
      "       device='cuda:0', requires_grad=True) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : Parameter containing:\n",
      "tensor([-0.0094,  0.0172, -0.0141,  0.0283,  0.0170, -0.0005, -0.0133, -0.0075,\n",
      "        -0.0180,  0.0051,  0.0007, -0.0055,  0.0149, -0.0133, -0.0167, -0.0171,\n",
      "        -0.0190, -0.0048, -0.0124, -0.0061,  0.0011, -0.0176, -0.0254, -0.0104,\n",
      "        -0.0019,  0.0285,  0.0272, -0.0196, -0.0159,  0.0154, -0.0183, -0.0075,\n",
      "         0.0160, -0.0017,  0.0231,  0.0063, -0.0317,  0.0118, -0.0297, -0.0262,\n",
      "        -0.0192, -0.0199, -0.0042,  0.0228, -0.0283,  0.0071,  0.0060,  0.0341,\n",
      "         0.0090, -0.0264, -0.0266,  0.0091,  0.0161, -0.0187,  0.0026, -0.0240,\n",
      "         0.0050,  0.0306,  0.0057,  0.0330,  0.0323, -0.0032, -0.0198,  0.0260,\n",
      "        -0.0015, -0.0330,  0.0278, -0.0339, -0.0007,  0.0313, -0.0160, -0.0349,\n",
      "         0.0200,  0.0188, -0.0330,  0.0171,  0.0099, -0.0272, -0.0009,  0.0173,\n",
      "         0.0078,  0.0036, -0.0185,  0.0204,  0.0051,  0.0146,  0.0307,  0.0341,\n",
      "         0.0041, -0.0171,  0.0295, -0.0139,  0.0068, -0.0291,  0.0088,  0.0149,\n",
      "        -0.0083,  0.0166,  0.0145, -0.0025,  0.0274, -0.0044, -0.0102, -0.0050,\n",
      "        -0.0246, -0.0169, -0.0322, -0.0071,  0.0302, -0.0056,  0.0244, -0.0248,\n",
      "         0.0238,  0.0136, -0.0021, -0.0103, -0.0146, -0.0323,  0.0102,  0.0142,\n",
      "         0.0071,  0.0354,  0.0322,  0.0286, -0.0036, -0.0064, -0.0251, -0.0119,\n",
      "        -0.0253,  0.0205,  0.0038, -0.0090, -0.0334, -0.0179,  0.0144,  0.0042,\n",
      "        -0.0118,  0.0204, -0.0063,  0.0293,  0.0088,  0.0234,  0.0313, -0.0226,\n",
      "         0.0351,  0.0078, -0.0326,  0.0091,  0.0175, -0.0122,  0.0018, -0.0058,\n",
      "         0.0280,  0.0004,  0.0237, -0.0299, -0.0179, -0.0320, -0.0027,  0.0146,\n",
      "         0.0332, -0.0011, -0.0271, -0.0179,  0.0299,  0.0169, -0.0156,  0.0343,\n",
      "         0.0114,  0.0093, -0.0353,  0.0257,  0.0325,  0.0041,  0.0191,  0.0223,\n",
      "         0.0205, -0.0231,  0.0057,  0.0272, -0.0064, -0.0272,  0.0305, -0.0351,\n",
      "        -0.0156, -0.0045,  0.0243, -0.0217, -0.0346, -0.0003, -0.0247, -0.0319,\n",
      "         0.0049, -0.0266,  0.0063, -0.0251, -0.0248,  0.0167,  0.0292, -0.0260,\n",
      "        -0.0203,  0.0046, -0.0062,  0.0289,  0.0062,  0.0219,  0.0183,  0.0251,\n",
      "        -0.0072, -0.0167, -0.0154, -0.0027,  0.0038,  0.0237,  0.0025,  0.0254,\n",
      "         0.0150,  0.0281, -0.0083,  0.0147, -0.0022,  0.0355, -0.0053, -0.0250,\n",
      "         0.0144,  0.0116, -0.0222, -0.0045, -0.0180, -0.0024, -0.0023,  0.0243,\n",
      "        -0.0294,  0.0348, -0.0298, -0.0264,  0.0099, -0.0345,  0.0075, -0.0346,\n",
      "        -0.0323, -0.0094,  0.0103,  0.0267, -0.0147, -0.0144, -0.0179,  0.0310,\n",
      "         0.0241, -0.0220, -0.0230,  0.0255,  0.0300,  0.0081,  0.0021, -0.0050,\n",
      "         0.0100,  0.0293, -0.0311,  0.0318,  0.0072,  0.0033,  0.0172,  0.0334,\n",
      "         0.0235,  0.0118,  0.0014, -0.0299, -0.0181, -0.0118,  0.0053, -0.0257,\n",
      "         0.0229,  0.0120, -0.0294, -0.0068, -0.0060,  0.0277,  0.0090, -0.0277,\n",
      "         0.0325, -0.0209,  0.0075,  0.0031,  0.0172, -0.0174, -0.0337,  0.0212,\n",
      "         0.0323, -0.0130,  0.0151,  0.0247,  0.0178, -0.0098, -0.0304, -0.0272,\n",
      "         0.0266, -0.0038,  0.0145, -0.0304, -0.0234, -0.0119, -0.0341,  0.0165,\n",
      "        -0.0263, -0.0026, -0.0289,  0.0056, -0.0016,  0.0052,  0.0240, -0.0059,\n",
      "         0.0163,  0.0255,  0.0088, -0.0089,  0.0339, -0.0072, -0.0105,  0.0018,\n",
      "         0.0070,  0.0246, -0.0134,  0.0064, -0.0261,  0.0097, -0.0023,  0.0168,\n",
      "         0.0075, -0.0089, -0.0251, -0.0231, -0.0282, -0.0163, -0.0302,  0.0021,\n",
      "        -0.0326, -0.0153, -0.0339,  0.0185,  0.0306,  0.0094, -0.0253, -0.0188,\n",
      "         0.0239,  0.0189, -0.0293, -0.0189, -0.0004,  0.0241,  0.0111, -0.0267,\n",
      "        -0.0063,  0.0205, -0.0023, -0.0055, -0.0303, -0.0209,  0.0286,  0.0107,\n",
      "         0.0258, -0.0318,  0.0233,  0.0150, -0.0356, -0.0083,  0.0087, -0.0300,\n",
      "        -0.0351,  0.0054,  0.0078,  0.0140,  0.0342, -0.0100,  0.0060, -0.0084,\n",
      "         0.0057, -0.0004, -0.0054,  0.0166, -0.0326, -0.0240,  0.0180, -0.0062,\n",
      "         0.0283, -0.0079, -0.0153, -0.0069, -0.0071,  0.0204,  0.0280,  0.0005,\n",
      "        -0.0175,  0.0324, -0.0039, -0.0002,  0.0019,  0.0180, -0.0254,  0.0303,\n",
      "        -0.0029, -0.0081, -0.0173, -0.0161,  0.0151,  0.0145,  0.0166,  0.0280,\n",
      "        -0.0179, -0.0100,  0.0200, -0.0333,  0.0343,  0.0095, -0.0194,  0.0067,\n",
      "        -0.0171, -0.0109, -0.0297,  0.0161, -0.0192,  0.0192, -0.0006, -0.0012,\n",
      "         0.0117,  0.0230, -0.0207,  0.0018,  0.0115,  0.0041,  0.0176,  0.0192,\n",
      "         0.0272,  0.0220,  0.0305,  0.0120, -0.0201,  0.0182,  0.0293,  0.0072,\n",
      "        -0.0334,  0.0143, -0.0057, -0.0294,  0.0164, -0.0023, -0.0334, -0.0147,\n",
      "         0.0041, -0.0028,  0.0103, -0.0355, -0.0210, -0.0173,  0.0002, -0.0044,\n",
      "        -0.0067,  0.0128,  0.0131,  0.0162,  0.0205,  0.0228,  0.0202,  0.0207,\n",
      "         0.0250,  0.0184,  0.0255,  0.0131, -0.0287,  0.0328, -0.0081,  0.0337,\n",
      "         0.0161, -0.0198,  0.0252, -0.0321,  0.0120,  0.0300, -0.0260,  0.0271,\n",
      "         0.0173, -0.0189, -0.0119,  0.0041, -0.0149,  0.0262,  0.0123,  0.0218,\n",
      "         0.0293, -0.0088,  0.0016, -0.0118,  0.0111,  0.0032, -0.0310, -0.0220,\n",
      "         0.0152,  0.0200, -0.0124, -0.0213, -0.0050,  0.0307,  0.0347,  0.0244,\n",
      "         0.0332, -0.0134,  0.0153, -0.0078,  0.0255,  0.0331, -0.0080, -0.0137],\n",
      "       device='cuda:0', requires_grad=True) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : Parameter containing:\n",
      "tensor([[ 0.0288,  0.0079,  0.0127,  ...,  0.0046,  0.0434,  0.0405],\n",
      "        [ 0.0438,  0.0002, -0.0138,  ..., -0.0279, -0.0384,  0.0308],\n",
      "        [ 0.0111, -0.0165,  0.0233,  ..., -0.0369,  0.0394,  0.0298],\n",
      "        ...,\n",
      "        [-0.0222,  0.0294, -0.0225,  ...,  0.0365,  0.0108, -0.0184],\n",
      "        [-0.0331,  0.0327, -0.0325,  ..., -0.0202, -0.0329, -0.0174],\n",
      "        [-0.0196, -0.0373,  0.0378,  ...,  0.0376, -0.0387, -0.0149]],\n",
      "       device='cuda:0', requires_grad=True) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : Parameter containing:\n",
      "tensor([-2.3986e-02, -5.2145e-03,  1.0102e-02, -1.1605e-02, -2.1457e-02,\n",
      "        -3.5359e-04, -7.8990e-03,  2.6194e-02, -2.9581e-02,  3.1624e-02,\n",
      "         3.0848e-02,  2.2704e-02, -1.6870e-02,  1.1702e-02,  1.0658e-02,\n",
      "        -2.7302e-02,  4.2196e-02, -3.9750e-02,  5.1729e-03, -8.6106e-03,\n",
      "        -3.9664e-02,  1.3711e-02,  1.7004e-02,  2.9748e-02,  2.4039e-02,\n",
      "         1.6726e-02, -1.2209e-03,  2.1243e-02, -1.5395e-02, -4.9366e-04,\n",
      "         9.3539e-03,  3.6933e-02, -4.2589e-02,  3.8253e-03, -4.4219e-04,\n",
      "        -2.5878e-02, -1.6900e-02,  3.8630e-02, -1.8578e-02,  3.0775e-02,\n",
      "        -2.2513e-02, -2.0442e-02, -4.2097e-02,  3.6988e-02, -3.9187e-02,\n",
      "         2.1499e-02,  3.7524e-02,  2.7982e-02, -3.9663e-02,  2.7325e-02,\n",
      "        -2.1977e-02, -3.6334e-02, -4.3125e-02, -1.2498e-02, -1.7904e-02,\n",
      "        -2.3210e-02, -6.8312e-04,  7.8946e-03, -2.3080e-02, -3.8646e-02,\n",
      "        -1.7959e-02, -1.1821e-02,  3.3203e-02,  1.8825e-02, -3.5453e-02,\n",
      "        -2.5522e-02, -8.1974e-03, -1.0141e-02, -3.0218e-02, -1.0280e-02,\n",
      "        -2.2086e-02, -3.4046e-03,  3.2839e-02, -4.1953e-02, -3.9941e-02,\n",
      "        -4.0697e-02,  2.0237e-02,  3.3552e-02,  1.5610e-02, -5.3335e-03,\n",
      "         7.5530e-03,  6.3321e-03,  3.1299e-02, -2.8050e-02,  1.4882e-02,\n",
      "         9.1811e-03, -7.8708e-03, -9.4966e-03, -2.1946e-02, -9.6840e-03,\n",
      "         4.3237e-02, -3.7971e-02,  4.1603e-02, -4.1596e-02, -2.2105e-02,\n",
      "         2.6457e-02,  8.2824e-03,  4.3502e-02,  2.7073e-02,  1.4474e-02,\n",
      "         6.0455e-03, -9.3752e-03, -7.1707e-03,  2.9681e-02, -3.1620e-02,\n",
      "        -1.9955e-02,  2.9319e-02,  3.8951e-02, -4.5104e-03,  3.8402e-02,\n",
      "         2.5907e-02, -9.7602e-03,  4.1869e-02,  3.5920e-02,  2.5325e-02,\n",
      "         1.1303e-02, -3.5942e-02,  3.1954e-02,  3.0241e-02, -3.4106e-02,\n",
      "        -2.4138e-02, -4.2227e-02,  1.2581e-02,  2.7387e-02, -8.9453e-03,\n",
      "        -4.5497e-03,  7.2610e-03,  4.0233e-02, -4.0955e-02, -4.1305e-03,\n",
      "         6.2296e-04,  2.7385e-02,  3.6724e-02, -1.6172e-02, -3.8072e-02,\n",
      "         4.1284e-02,  5.3709e-03,  2.7086e-02,  3.9089e-02,  3.4040e-02,\n",
      "         4.1076e-02,  4.1764e-02, -2.0384e-02,  1.2105e-02,  2.5320e-02,\n",
      "         1.2499e-03, -2.3800e-02, -2.1289e-02,  1.3877e-02,  2.0859e-02,\n",
      "        -1.6283e-02,  2.5152e-02, -1.9137e-02,  2.5154e-03, -1.7149e-02,\n",
      "        -1.1129e-02, -6.9156e-03, -2.3013e-02,  3.5653e-02, -3.8127e-02,\n",
      "         4.0151e-02, -1.9400e-02,  1.6036e-02,  3.2500e-02, -3.4601e-02,\n",
      "         2.4224e-02,  3.6043e-02, -3.3884e-02,  4.3140e-02, -2.2999e-02,\n",
      "         1.8033e-02, -4.2052e-02, -3.8412e-02, -3.8455e-02, -1.1287e-03,\n",
      "        -4.2878e-02, -1.4007e-02, -1.7638e-02, -2.6378e-02, -3.2951e-02,\n",
      "        -1.5025e-02,  2.4208e-02, -1.2173e-02,  1.8626e-02, -2.4158e-03,\n",
      "        -1.5252e-02, -2.0958e-02,  3.7475e-02,  3.3329e-02, -5.4297e-03,\n",
      "         3.5993e-02,  1.6893e-02, -1.9270e-02, -2.2557e-03, -1.2864e-02,\n",
      "        -1.1030e-02,  3.8544e-02,  3.9255e-02, -3.0334e-02,  4.3695e-03,\n",
      "        -4.2418e-02, -7.4392e-03,  1.1172e-02,  9.5003e-03,  4.1416e-02,\n",
      "        -4.0753e-02, -3.2506e-02, -2.6131e-02,  3.9485e-02,  3.5805e-02,\n",
      "        -2.3057e-02,  3.3986e-02,  1.8133e-02,  4.0186e-02,  3.3755e-02,\n",
      "        -3.3734e-03, -1.6816e-02,  2.3492e-02,  3.1596e-02, -7.3104e-03,\n",
      "        -1.2760e-02, -8.0551e-03, -2.8415e-03,  1.4872e-02,  3.8995e-02,\n",
      "         1.8968e-03,  3.3360e-02, -1.3318e-02,  6.1830e-03,  2.8714e-03,\n",
      "        -5.1752e-03, -3.5576e-02, -3.0964e-02, -2.7365e-02, -1.5243e-03,\n",
      "         1.8117e-02,  1.6528e-02,  2.6744e-02,  7.5123e-03,  1.8244e-02,\n",
      "        -2.9070e-02,  5.3604e-03,  1.2805e-02,  2.0792e-02, -3.3067e-02,\n",
      "        -3.8090e-02, -2.4646e-02, -3.3478e-02,  8.0039e-03,  2.4805e-02,\n",
      "         3.5119e-02,  5.7450e-03,  1.9500e-02,  4.1771e-02, -1.4457e-02,\n",
      "         4.0208e-02, -3.1934e-02,  3.4475e-02, -1.5397e-02,  5.7814e-03,\n",
      "         3.4729e-02, -4.1388e-02, -4.1633e-02,  3.9356e-02,  6.6451e-03,\n",
      "        -3.4006e-02,  7.0258e-03, -3.5167e-02,  3.8104e-02,  3.5318e-02,\n",
      "         2.5411e-02, -3.4958e-02,  1.3313e-03, -1.6499e-02, -2.6197e-02,\n",
      "        -1.0127e-02, -4.3376e-02, -3.1428e-02,  4.2494e-02,  2.7836e-02,\n",
      "         1.5154e-02, -3.5914e-02, -5.4260e-03, -3.7070e-02,  1.0640e-02,\n",
      "         3.4144e-02, -3.6845e-02, -2.9131e-02, -8.2895e-03, -1.2561e-02,\n",
      "        -2.7152e-02, -3.8193e-02,  3.1781e-02, -2.0693e-02, -7.1377e-03,\n",
      "         2.7743e-02,  4.3010e-02, -3.8255e-02,  1.4182e-02,  3.0265e-02,\n",
      "        -8.2384e-03, -2.6069e-02, -3.0339e-02, -2.4873e-02,  1.9871e-02,\n",
      "         4.3974e-02, -4.3566e-02, -2.5737e-02, -1.4054e-02,  1.5113e-02,\n",
      "         3.8661e-02, -3.4646e-02, -9.4083e-03, -1.1266e-02,  3.9427e-02,\n",
      "        -3.6658e-02,  3.2932e-02,  3.5393e-02, -2.6480e-02, -5.0709e-03,\n",
      "        -3.5068e-02,  2.4309e-02,  2.1642e-02, -1.5669e-02, -4.3232e-02,\n",
      "         3.0264e-02,  1.3413e-02,  2.5483e-02, -2.7508e-02, -2.0851e-02,\n",
      "         3.5319e-02, -3.3734e-02, -2.4836e-02, -5.9809e-03,  6.2029e-04,\n",
      "        -3.0427e-03,  1.9731e-02,  1.5298e-02,  2.7244e-02, -1.7692e-02,\n",
      "         1.3552e-02, -1.0215e-02, -4.1756e-02, -9.3106e-03,  2.5653e-02,\n",
      "         4.0891e-02,  1.7433e-02,  1.2573e-02, -3.6620e-02, -2.2836e-02,\n",
      "        -2.0876e-02,  9.3723e-03,  1.1589e-02, -1.4522e-02, -4.3802e-02,\n",
      "        -2.0493e-02, -3.6407e-02, -3.5582e-04,  3.3319e-02, -4.4031e-02,\n",
      "        -1.7325e-02, -1.3302e-02, -3.4374e-02, -4.4133e-02,  2.1659e-03,\n",
      "         3.1028e-02,  3.1648e-02, -3.8523e-02,  8.8910e-03,  2.3483e-02,\n",
      "        -2.4460e-03, -2.2545e-02,  3.0886e-03,  2.2109e-02,  2.0136e-02,\n",
      "         2.3740e-02, -2.0052e-02,  2.4342e-02,  4.3396e-02,  9.0874e-04,\n",
      "         2.1862e-03,  2.6309e-02,  3.7593e-02,  2.1520e-02,  8.7572e-03,\n",
      "         3.5530e-02,  2.4341e-02,  4.3373e-02, -3.3315e-02, -2.7616e-02,\n",
      "        -7.1177e-03,  1.0641e-02,  8.1429e-03, -3.2275e-02,  1.1627e-02,\n",
      "        -3.8169e-02, -4.1943e-02,  7.5021e-06,  2.4861e-02, -2.4468e-02,\n",
      "        -1.4493e-02,  1.9101e-02,  5.4010e-03,  1.3964e-02,  2.2553e-02,\n",
      "         2.2195e-02,  4.0437e-02, -8.6341e-03, -3.2573e-02,  3.5661e-02,\n",
      "        -3.0022e-02, -2.6263e-02,  2.0720e-02, -3.6714e-02, -5.6763e-03,\n",
      "        -2.9293e-02,  1.9831e-02,  1.9782e-02,  1.9785e-02, -1.6961e-02,\n",
      "        -2.5945e-02,  4.2800e-02, -3.7909e-02,  1.2246e-02,  7.5263e-03,\n",
      "        -3.1827e-03, -4.3306e-02,  4.2166e-02,  2.0324e-02,  1.3473e-02,\n",
      "         2.0722e-02, -4.3980e-02,  1.7248e-02, -2.0688e-02, -3.0169e-03,\n",
      "        -9.3487e-03, -3.7268e-02,  2.4020e-02,  2.3536e-02,  1.0005e-02,\n",
      "         3.7189e-02, -2.6210e-02,  1.3382e-02, -1.1174e-02, -3.2491e-02,\n",
      "         2.4240e-02,  2.5581e-02,  4.2796e-02,  1.2910e-02,  3.9992e-02,\n",
      "         2.7678e-02, -2.4404e-02, -6.4808e-03, -2.5448e-02,  2.1528e-02,\n",
      "        -2.1916e-02, -4.0785e-02,  1.3858e-02,  4.1485e-02,  3.6799e-02,\n",
      "        -3.7206e-02,  1.1351e-03,  2.6569e-02, -2.5249e-02, -1.0915e-02,\n",
      "         3.3547e-02,  3.7312e-02, -4.1662e-02,  2.7531e-02,  2.1214e-02,\n",
      "         2.8482e-02,  1.3368e-02,  9.0333e-03, -1.8046e-02,  9.7109e-04,\n",
      "        -4.1278e-02,  3.2719e-02, -2.2251e-02, -5.5278e-03, -1.2345e-02,\n",
      "        -3.5980e-02, -2.8647e-02,  1.4255e-02, -1.3629e-02, -1.5389e-02,\n",
      "         1.8865e-02,  3.9656e-03,  1.2047e-02, -3.0388e-02,  4.9875e-03,\n",
      "         4.3409e-02, -3.2705e-02, -4.0022e-02,  2.3035e-02,  2.5036e-02,\n",
      "         2.5414e-02, -2.4314e-02,  3.5649e-02,  4.8950e-03,  1.1174e-02,\n",
      "         3.3078e-02, -1.3662e-03,  5.0161e-03, -1.4326e-02, -1.8809e-02,\n",
      "         1.3344e-02, -1.6935e-02, -2.8674e-02,  2.8137e-02,  2.0313e-03,\n",
      "         2.4402e-02,  2.4886e-02], device='cuda:0', requires_grad=True) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : Parameter containing:\n",
      "tensor([[ 0.0079, -0.0304, -0.0394,  ..., -0.0242, -0.0256, -0.0283],\n",
      "        [ 0.0081,  0.0391,  0.0178,  ...,  0.0082, -0.0039, -0.0050],\n",
      "        [ 0.0134, -0.0350, -0.0188,  ...,  0.0308, -0.0253,  0.0247],\n",
      "        ...,\n",
      "        [-0.0377,  0.0060,  0.0167,  ...,  0.0099,  0.0239, -0.0172],\n",
      "        [ 0.0312,  0.0359,  0.0428,  ...,  0.0243, -0.0232,  0.0145],\n",
      "        [-0.0027,  0.0074, -0.0362,  ...,  0.0070, -0.0064,  0.0182]],\n",
      "       device='cuda:0', requires_grad=True) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : Parameter containing:\n",
      "tensor([ 0.0337,  0.0043,  0.0368, -0.0133,  0.0253,  0.0101,  0.0237, -0.0079,\n",
      "        -0.0075,  0.0369], device='cuda:0', requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
